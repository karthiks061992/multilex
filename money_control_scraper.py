# -*- coding: utf-8 -*-
"""money_control_scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17jYHPZxdt-2t_Mon96D7lK0KIkXfMhFQ
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup
article=[]
links=[]
def money_control():
  
  for i in range(0,198):
    URL = "https://www.moneycontrol.com/news/business/ipo/page-"+str(i)
    page = requests.get(URL)

    soup = BeautifulSoup(page.content, 'html.parser')
    for j in range(1,len(soup.find_all('h2'))):
      x=soup.find_all('h2')[j].get_text()
      if x not in article:
        #print(x)
        article.append(x)
      y=soup.find_all('h2')[j]
      for a in y.find_all('a',href=True):
        # link=y.find_all('a',href=True)
        if a["href"] not in links:
          #print(a["href"])
          links.append(a["href"])
  df = pd.DataFrame(article,columns=['articles'])
  return df

df_final=money_control()
#df_final
df_final=df_final.drop(0)
#df_final
df_final=df_final.reindex()
df_final

import spacy 
import pandas as pd
company_dict={}
link_dict={}
nlpq = spacy.load('en_core_web_sm')
for i in range(1,df_final["articles"].shape[0]):
  doc=nlpq(df_final["articles"][i])
  for ele in doc.ents:
    if ele.label_=='ORG':
      company_dict[df_final['articles'][i]]=ele
      link_dict[df_final['articles'][i]]=links[i-1]



final_dict={}
flag=False
keywords=['IPO,','pre-ipo','PRE-IPO','going public','Pre-IPO','ipo','IPO']
for key in company_dict:
  lis=key.split(" ")
  #print(lis)
  for word in lis:
    if word in keywords:
      print(key)
      final_dict[key]=company_dict[key]
      break

# for key in final_dict:
#   print(final_dict[key])
final_df=pd.DataFrame(columns=['articles','companies'])
final_df['companies']=final_dict.values()
final_df['articles']=final_dict.keys()

final_df

# from google.colab import drive
# drive.mount('drive')

# final_df.to_csv('money.csv')
# !cp money.csv "drive/My Drive/"















