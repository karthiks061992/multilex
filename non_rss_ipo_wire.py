# -*- coding: utf-8 -*-
"""non_rss_ipo_wire.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ehwj4KN6sSsxlzG00Pnzix_oKsZ9pUTG
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import requests
from bs4 import BeautifulSoup

articles=[]
links=[]
dates=[]
for j in range(1,53):
  URL="https://ipo.einnews.com/?page="+str(j)
  page=requests.get(URL)
  soup=BeautifulSoup(page.content,'html.parser')
  for i in range(1,len(soup.find_all('h3'))-31):
    if soup.find_all('h3')[i].get_text() not in articles:
      pdd=soup.find_all('h3')[i]
      articles.append(soup.find_all('h3')[i].get_text())
      for a in pdd.find_all('a',href=True):
        links.append(a["href"])
      dates.append(soup.find_all('span',{'class':'date'})[i].get_text())

cleaned_articles=[]
import re
for article in articles:
  cleanString = re.sub('\n','', article)
  cleaned_articles.append(cleanString)
len(cleaned_articles)

orgs=[]
for i in range(0,len(cleaned_articles)):
  orgs.append('orgs')
df = pd.DataFrame(list(zip(cleaned_articles,links,dates,orgs)), 
               columns =['Text', 'Links','Dates','Organization'])

import spacy
nlpq = spacy.load('en_core_web_sm')
for i in range(0,df.shape[0]):
  article=df['Text'][i]
  doc=nlpq(article)
  for ele in doc.ents:
    if ele.label_=='ORG':
      df['Organization'][i]=ele
    else:
      df['Organization'][i]="organization not found"

df

from google.colab import drive
drive.mount('drive')

df.to_csv('full_scraper_IPO_20th.csv')
!cp full_scraper_IPO_20th.csv "drive/My Drive/"